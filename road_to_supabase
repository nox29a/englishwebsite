-- Enable required extensions
create extension if not exists "pgcrypto";

-- Courses and content hierarchy
create table if not exists public.courses (
  id uuid primary key default gen_random_uuid(),
  slug text not null unique,
  title text not null,
  description text,
  level text,
  created_at timestamptz not null default now()
);

create table if not exists public.modules (
  id uuid primary key default gen_random_uuid(),
  course_id uuid not null references public.courses(id) on delete cascade,
  slug text not null,
  title text not null,
  description text,
  sort_order int not null default 0,
  created_at timestamptz not null default now(),
  unique (course_id, slug)
);

create table if not exists public.lessons (
  id uuid primary key default gen_random_uuid(),
  module_id uuid not null references public.modules(id) on delete cascade,
  slug text not null,
  title text not null,
  description text,
  difficulty text,
  sort_order int not null default 0,
  created_at timestamptz not null default now(),
  unique (module_id, slug)
);

create table if not exists public.exercise_templates (
  id uuid primary key default gen_random_uuid(),
  lesson_id uuid references public.lessons(id) on delete set null,
  template_type text not null,
  skill_tags text[] default array[]::text[],
  difficulty text,
  content_source text,
  configuration jsonb default '{}'::jsonb,
  created_at timestamptz not null default now()
);

-- Sessions and attempts
create table if not exists public.exercise_sessions (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references auth.users(id) on delete cascade,
  lesson_id uuid references public.lessons(id) on delete set null,
  started_at timestamptz not null default now(),
  ended_at timestamptz,
  duration_seconds int generated always as (
    case
      when ended_at is null then null
      else greatest(1, extract(epoch from ended_at - started_at)::int)
    end
  ) stored,
  source text,
  created_at timestamptz not null default now()
);

create table if not exists public.exercise_attempts (
  id uuid primary key default gen_random_uuid(),
  session_id uuid not null references public.exercise_sessions(id) on delete cascade,
  user_id uuid not null references auth.users(id) on delete cascade,
  template_id uuid references public.exercise_templates(id) on delete set null,
  skill_tags text[] default array[]::text[],
  started_at timestamptz not null default now(),
  completed_at timestamptz,
  total_questions int not null default 0,
  correct_answers int not null default 0,
  incorrect_answers int not null default 0,
  skipped_answers int not null default 0,
  score numeric(5,2),
  mastery numeric(5,2),
  metadata jsonb default '{}'::jsonb,
  created_at timestamptz not null default now()
);

create table if not exists public.answer_events (
  id uuid primary key default gen_random_uuid(),
  attempt_id uuid not null references public.exercise_attempts(id) on delete cascade,
  user_id uuid not null references auth.users(id) on delete cascade,
  question_identifier text,
  prompt text,
  expected_answer text,
  user_answer text,
  is_correct boolean not null,
  latency_ms int,
  skill_tag text,
  created_at timestamptz not null default now()
);

-- Error tracking
create table if not exists public.error_taxonomy (
  id uuid primary key default gen_random_uuid(),
  code text not null unique,
  name text not null,
  category text not null,
  description text,
  created_at timestamptz not null default now()
);

create table if not exists public.mistakes (
  id uuid primary key default gen_random_uuid(),
  answer_event_id uuid not null references public.answer_events(id) on delete cascade,
  taxonomy_id uuid not null references public.error_taxonomy(id) on delete cascade,
  user_id uuid not null references auth.users(id) on delete cascade,
  severity text not null default 'medium',
  note text,
  created_at timestamptz not null default now()
);

create table if not exists public.remediation_actions (
  id uuid primary key default gen_random_uuid(),
  taxonomy_id uuid not null references public.error_taxonomy(id) on delete cascade,
  title text not null,
  description text,
  resource_url text,
  created_at timestamptz not null default now()
);

-- Metrics and analytics
create table if not exists public.daily_metrics (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references auth.users(id) on delete cascade,
  metrics_date date not null,
  total_sessions int not null default 0,
  total_attempts int not null default 0,
  correct_answers int not null default 0,
  incorrect_answers int not null default 0,
  skipped_answers int not null default 0,
  total_time_seconds int not null default 0,
  average_latency_ms numeric(10,2),
  xp_gained int not null default 0,
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  unique (user_id, metrics_date)
);

create table if not exists public.skill_snapshots (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references auth.users(id) on delete cascade,
  skill_key text not null,
  proficiency numeric(5,2) not null default 0,
  evidence_count int not null default 0,
  computed_at timestamptz not null default now(),
  unique (user_id, skill_key, computed_at)
);

create table if not exists public.streaks (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null unique references auth.users(id) on delete cascade,
  current_streak int not null default 0,
  longest_streak int not null default 0,
  last_active_date date,
  updated_at timestamptz not null default now()
);

create table if not exists public.xp_history (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references auth.users(id) on delete cascade,
  source text,
  amount int not null,
  occurred_at timestamptz not null default now(),
  metadata jsonb default '{}'::jsonb
);

create table if not exists public.lesson_prerequisites (
  lesson_id uuid not null references public.lessons(id) on delete cascade,
  prerequisite_lesson_id uuid not null references public.lessons(id) on delete cascade,
  created_at timestamptz not null default now(),
  primary key (lesson_id, prerequisite_lesson_id)
);

create table if not exists public.content_versions (
  id uuid primary key default gen_random_uuid(),
  lesson_id uuid references public.lessons(id) on delete set null,
  version_number int not null,
  released_at timestamptz not null default now(),
  change_summary text,
  unique (lesson_id, version_number)
);

create table if not exists public.early_warning_flags (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references auth.users(id) on delete cascade,
  reason text not null,
  triggered_at timestamptz not null default now(),
  resolved_at timestamptz,
  metadata jsonb default '{}'::jsonb
);

-- Indexes
create index if not exists idx_modules_course on public.modules(course_id);
create index if not exists idx_lessons_module on public.lessons(module_id);
create index if not exists idx_exercise_sessions_user on public.exercise_sessions(user_id);
create index if not exists idx_exercise_sessions_lesson on public.exercise_sessions(lesson_id);
create index if not exists idx_exercise_attempts_user on public.exercise_attempts(user_id);
create index if not exists idx_answer_events_user on public.answer_events(user_id);
create index if not exists idx_answer_events_skill on public.answer_events(skill_tag);
create index if not exists idx_mistakes_user on public.mistakes(user_id);
create index if not exists idx_daily_metrics_user_date on public.daily_metrics(user_id, metrics_date desc);
create index if not exists idx_skill_snapshots_user on public.skill_snapshots(user_id, skill_key);
create index if not exists idx_xp_history_user on public.xp_history(user_id);

-- Helper views
create or replace view public.view_student_overview as
select
  u.id as user_id,
  coalesce(sum(dm.correct_answers), 0) as total_correct_answers,
  coalesce(sum(dm.total_attempts), 0) as total_attempts,
  coalesce(sum(dm.total_time_seconds), 0) as total_time_seconds,
  coalesce(sum(dm.xp_gained), 0) as total_xp,
  max(ss.proficiency) filter (where ss.skill_key = 'vocabulary') as vocabulary_mastery,
  max(ss.proficiency) filter (where ss.skill_key = 'grammar') as grammar_mastery,
  max(ss.proficiency) filter (where ss.skill_key = 'listening') as listening_mastery,
  max(ss.proficiency) filter (where ss.skill_key = 'speaking') as speaking_mastery
from auth.users u
left join public.daily_metrics dm on dm.user_id = u.id
left join public.skill_snapshots ss on ss.user_id = u.id
where u.id = auth.uid()
group by u.id;

create or replace view public.view_mistake_heatmap as
select
  m.user_id,
  et.category,
  et.code,
  date_trunc('day', ae.created_at)::date as metrics_date,
  count(*) as mistakes_count
from public.mistakes m
join public.error_taxonomy et on et.id = m.taxonomy_id
join public.answer_events ae on ae.id = m.answer_event_id
where m.user_id = auth.uid()
group by m.user_id, et.category, et.code, metrics_date;

create or replace view public.view_xp_leaderboard as
select
  x.user_id,
  sum(x.amount) as total_xp,
  max(x.occurred_at) as last_activity
from public.xp_history x
group by x.user_id;

-- Functions for automatic metric updates
create or replace function public.upsert_daily_metrics_for_session()
returns trigger as $$
declare
  metrics_day date := (coalesce(new.ended_at, new.started_at))::date;
begin
  if metrics_day is null then
    return new;
  end if;

  insert into public.daily_metrics (user_id, metrics_date, total_sessions, total_time_seconds)
  values (new.user_id, metrics_day, 1, coalesce(new.duration_seconds, 0))
  on conflict (user_id, metrics_date) do update
  set total_sessions = public.daily_metrics.total_sessions + 1,
      total_time_seconds = public.daily_metrics.total_time_seconds + coalesce(excluded.total_time_seconds, 0),
      updated_at = now();

  return new;
end;
$$ language plpgsql;

create or replace function public.upsert_daily_metrics_for_attempt()
returns trigger as $$
declare
  metrics_day date := coalesce(new.completed_at, new.started_at)::date;
begin
  if metrics_day is null then
    return new;
  end if;

  insert into public.daily_metrics (
    user_id,
    metrics_date,
    total_attempts,
    correct_answers,
    incorrect_answers,
    skipped_answers
  ) values (
    new.user_id,
    metrics_day,
    new.total_questions,
    new.correct_answers,
    new.incorrect_answers,
    new.skipped_answers
  )
  on conflict (user_id, metrics_date) do update
  set total_attempts = public.daily_metrics.total_attempts + excluded.total_attempts,
      correct_answers = public.daily_metrics.correct_answers + excluded.correct_answers,
      incorrect_answers = public.daily_metrics.incorrect_answers + excluded.incorrect_answers,
      skipped_answers = public.daily_metrics.skipped_answers + excluded.skipped_answers,
      updated_at = now();

  return new;
end;
$$ language plpgsql;

create or replace function public.upsert_daily_metrics_for_answer()
returns trigger as $$
declare
  metrics_day date := new.created_at::date;
  latency numeric := new.latency_ms;
begin
  insert into public.daily_metrics (
    user_id,
    metrics_date,
    total_attempts,
    correct_answers,
    incorrect_answers,
    average_latency_ms
  ) values (
    new.user_id,
    metrics_day,
    1,
    case when new.is_correct then 1 else 0 end,
    case when new.is_correct then 0 else 1 end,
    latency
  )
  on conflict (user_id, metrics_date) do update
  set total_attempts = public.daily_metrics.total_attempts + 1,
      correct_answers = public.daily_metrics.correct_answers + (case when new.is_correct then 1 else 0 end),
      incorrect_answers = public.daily_metrics.incorrect_answers + (case when new.is_correct then 0 else 1 end),
      average_latency_ms =
        case
          when public.daily_metrics.average_latency_ms is null then latency
          when latency is null then public.daily_metrics.average_latency_ms
          else (public.daily_metrics.average_latency_ms + latency) / 2
        end,
      updated_at = now();

  return new;
end;
$$ language plpgsql;

create or replace function public.upsert_skill_snapshot()
returns trigger as $$
declare
  skill text;
  mastery numeric;
  evidence int;
begin
  if new.skill_tags is null then
    return new;
  end if;

  foreach skill in array new.skill_tags loop
    mastery := case when new.total_questions = 0 then 0 else (new.correct_answers::numeric / new.total_questions::numeric) * 100 end;
    evidence := new.total_questions;

    insert into public.skill_snapshots (user_id, skill_key, proficiency, evidence_count, computed_at)
    values (new.user_id, skill, mastery, evidence, coalesce(new.completed_at, now()))
    on conflict (user_id, skill_key, computed_at) do update
    set proficiency = excluded.proficiency,
        evidence_count = excluded.evidence_count,
        computed_at = excluded.computed_at;
  end loop;

  return new;
end;
$$ language plpgsql;

create or replace function public.update_streak_on_metric()
returns trigger as $$
declare
  streak_record public.streaks;
  gap int;
begin
  select * into streak_record from public.streaks where user_id = new.user_id;

  if not found then
    insert into public.streaks (user_id, current_streak, longest_streak, last_active_date)
    values (new.user_id, 1, 1, new.metrics_date);
    return new;
  end if;

  if streak_record.last_active_date = new.metrics_date then
    return new;
  end if;

  gap := new.metrics_date - streak_record.last_active_date;

  if gap = 1 then
    update public.streaks
      set current_streak = streak_record.current_streak + 1,
          longest_streak = greatest(streak_record.longest_streak, streak_record.current_streak + 1),
          last_active_date = new.metrics_date,
          updated_at = now()
    where user_id = new.user_id;
  else
    update public.streaks
      set current_streak = 1,
          last_active_date = new.metrics_date,
          updated_at = now()
    where user_id = new.user_id;
  end if;

  return new;
end;
$$ language plpgsql;

create or replace function public.raise_early_warning_flag()
returns trigger as $$
declare
  failures int;
  threshold int := 5;
begin
  if new.is_correct then
    return new;
  end if;

  select count(*) into failures
  from public.answer_events
  where user_id = new.user_id
    and created_at >= now() - interval '1 day'
    and is_correct = false;

  if failures >= threshold then
    insert into public.early_warning_flags (user_id, reason, metadata)
    values (new.user_id, 'excessive_incorrect_answers', jsonb_build_object('failures', failures))
    on conflict do nothing;
  end if;

  return new;
end;
$$ language plpgsql;

-- Triggers
create trigger trg_daily_metrics_session
  after insert on public.exercise_sessions
  for each row execute function public.upsert_daily_metrics_for_session();

create trigger trg_daily_metrics_attempt
  after insert on public.exercise_attempts
  for each row execute function public.upsert_daily_metrics_for_attempt();

create trigger trg_daily_metrics_answer
  after insert on public.answer_events
  for each row execute function public.upsert_daily_metrics_for_answer();

create trigger trg_skill_snapshots_attempt
  after insert on public.exercise_attempts
  for each row execute function public.upsert_skill_snapshot();

create trigger trg_streaks_daily_metrics
  after insert on public.daily_metrics
  for each row execute function public.update_streak_on_metric();

create trigger trg_early_warning_answer
  after insert on public.answer_events
  for each row execute function public.raise_early_warning_flag();

-- Row Level Security policies
alter table public.courses enable row level security;
alter table public.modules enable row level security;
alter table public.lessons enable row level security;
alter table public.exercise_templates enable row level security;
alter table public.exercise_sessions enable row level security;
alter table public.exercise_attempts enable row level security;
alter table public.answer_events enable row level security;
alter table public.error_taxonomy enable row level security;
alter table public.mistakes enable row level security;
alter table public.remediation_actions enable row level security;
alter table public.daily_metrics enable row level security;
alter table public.skill_snapshots enable row level security;
alter table public.streaks enable row level security;
alter table public.xp_history enable row level security;
alter table public.lesson_prerequisites enable row level security;
alter table public.content_versions enable row level security;
alter table public.early_warning_flags enable row level security;

create policy if not exists "Courses readable by all" on public.courses
  for select using (true);

create policy if not exists "Modules readable by all" on public.modules
  for select using (true);

create policy if not exists "Lessons readable by all" on public.lessons
  for select using (true);

create policy if not exists "Templates readable by all" on public.exercise_templates
  for select using (true);

create policy if not exists "Exercise sessions by owner" on public.exercise_sessions
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "Exercise attempts by owner" on public.exercise_attempts
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "Answer events by owner" on public.answer_events
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "Daily metrics by owner" on public.daily_metrics
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "Skill snapshots by owner" on public.skill_snapshots
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "Streaks by owner" on public.streaks
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "XP history by owner" on public.xp_history
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "XP history leaderboard read" on public.xp_history
  for select using (true);

create policy if not exists "Mistakes by owner" on public.mistakes
  for all using (user_id = auth.uid()) with check (user_id = auth.uid());

create policy if not exists "Remediation read" on public.remediation_actions
  for select using (true);

create policy if not exists "Error taxonomy read" on public.error_taxonomy
  for select using (true);

create policy if not exists "Lesson prerequisites read" on public.lesson_prerequisites
  for select using (true);

create policy if not exists "Content versions read" on public.content_versions
  for select using (true);

create policy if not exists "Early warning flags by owner" on public.early_warning_flags
  for select using (user_id = auth.uid());

-- Helper comment: refresh materialized views or schedule CRON via Supabase Dashboard as needed.
